{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('../shape_predictor_68_face_landmarks.dat')\n",
    "#Importing Image\n",
    "img = cv2.imread(\"../assets/img4.jpg\")\n",
    "# print(img.shape)\n",
    "if img.shape[0] > 500 and img.shape[1] > 500:\n",
    "    img = cv2.resize(img, (0,0), None, fx = 0.5, fy = 0.5)\n",
    "img_copy = img.copy()\n",
    "img_bw = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_detector(img_bw)\n",
    "# face_points = []\n",
    "for face in faces:\n",
    "    x1, y1 = face.left(), face.top()\n",
    "    x2, y2 = face.right(), face.bottom()\n",
    "    landmarks = predictor(img_bw, face)\n",
    "    x = [landmarks.part(i).x for i in range(68)]\n",
    "    y = [landmarks.part(i).y for i in range(68)]\n",
    "    face_points = [[i,j] for i,j in zip(x,y)]   \n",
    "img = cv2.polylines(img, [np.array(face_points[36:42])], True, (0,0,0),1, cv2.LINE_AA)\n",
    "img = cv2.polylines(img, [np.array(face_points[42:48])], True, (0,0,0),1, cv2.LINE_AA) \n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open shape_predictor_68_face_landmarks.dat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3a400f136623>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mface_detector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'shape_predictor_68_face_landmarks.dat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to open shape_predictor_68_face_landmarks.dat"
     ]
    }
   ],
   "source": [
    "\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('../shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "def empty(a):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"LipColor\")\n",
    "cv2.resizeWindow(\"LipColor\", 640, 240)\n",
    "cv2.createTrackbar(\"Blue\",'LipColor',0,255,empty)\n",
    "cv2.createTrackbar(\"Green\",'LipColor',0,255,empty)\n",
    "cv2.createTrackbar(\"Red\",'LipColor',0,255,empty)\n",
    "\n",
    "\n",
    "\n",
    "def createBoundBox(img,points,teeth_points, scale=2, masked=False, cropped=True):\n",
    "    #converting lists to numpy array\n",
    "    points = np.array(points)\n",
    "    teeth_points = np.array(teeth_points)\n",
    "\n",
    "    if masked:\n",
    "        #creating mask only for lips\n",
    "        mask = np.zeros_like(img)\n",
    "        mask = cv2.fillPoly(mask,[points], (255,255,255))\n",
    "        mask = cv2.fillPoly(mask,[teeth_points], (0,0,0))\n",
    "        img = cv2.bitwise_and(img, mask)\n",
    "\n",
    "    if cropped:\n",
    "        #getting starting (x,y) coordinate, width and height of image\n",
    "        x,y,w,h = cv2.boundingRect(points)\n",
    "        crop = img[y:y+h, x:x+w]\n",
    "        crop = cv2.resize(crop,(0,0),fx=scale, fy=scale)\n",
    "        return crop\n",
    "    else:\n",
    "        return mask\n",
    "\n",
    "while True:\n",
    "    img = cv2.imread(\"./assets/img1.jpg\")\n",
    "    if img.shape[0] > 500 and img.shape[1] > 500:\n",
    "        img = cv2.resize(img, (0,0), None, fx = 0.5, fy = 0.5)\n",
    "\n",
    "    img_copy = img.copy()\n",
    "    img_bw = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector(img_bw)\n",
    "    # face_points = []\n",
    "    for face in faces:\n",
    "        x1, y1 = face.left(), face.top()\n",
    "        x2, y2 = face.right(), face.bottom()\n",
    "        landmarks = predictor(img_bw, face)\n",
    "        x = [landmarks.part(i).x for i in range(68)]\n",
    "        y = [landmarks.part(i).y for i in range(68)]\n",
    "        face_points = [[i,j] for i,j in zip(x,y)]  \n",
    "\n",
    "    #Cropping Lips section\n",
    "    lips = createBoundBox(img, face_points[48:61], face_points[60:69], masked=True, cropped=False)\n",
    "    \n",
    "    #Coloring Lips\n",
    "    lip_color_img = np.zeros_like(lips)\n",
    "    b = cv2.getTrackbarPos('Blue',\"LipColor\")\n",
    "    g = cv2.getTrackbarPos('Green',\"LipColor\")\n",
    "    r = cv2.getTrackbarPos('Red',\"LipColor\")\n",
    "\n",
    "    lip_color_img[:] = b,g,r\n",
    "    lip_color_img = cv2.bitwise_and(lips, lip_color_img)\n",
    "    lip_color_img = cv2.GaussianBlur(lip_color_img, (7,7),10)\n",
    "    lip_color_img = cv2.addWeighted(img_copy, 1, lip_color_img,0.4,0)\n",
    "    # lip_color_img = cv2.resize(lip_color_img, (0,0), fx=1.5, fy=1.5)\n",
    "    # img_copy = cv2.resize(img_copy, (0,0), fx=1.5, fy=1.5)\n",
    "\n",
    "    collage = np.hstack((img_copy,lip_color_img))\n",
    "    cv2.imshow('LipColor', collage)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4,5,6]\n",
    "b = [2,4,6,8,10,12]\n",
    "b[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "656e673658cf815677d2185eedc11fbda4447bbdf81a7cd7c87ddba8fac50ff6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('segmn': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
